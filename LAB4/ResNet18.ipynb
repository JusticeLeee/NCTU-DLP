{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64ffe0d-4e88-4cb6-b4cb-34b19c7fb163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f52bab0-aeb5-4ba7-b7f7-5f83c32ae8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(mode):\n",
    "    if mode == 'train':\n",
    "        img = pd.read_csv('train_img.csv')\n",
    "        label = pd.read_csv('train_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)\n",
    "    else:\n",
    "        img = pd.read_csv('test_img.csv')\n",
    "        label = pd.read_csv('test_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7c1d73-5561-4ecb-91a7-4fe23883eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 28099 images...\n",
      "> Found 7025 images...\n"
     ]
    }
   ],
   "source": [
    "class RetinopathyLoader(data.Dataset):\n",
    "    def __init__(self, root, mode):\n",
    "    \n",
    "        self.root = root\n",
    "        # the type is numpy.ndarray\n",
    "        self.img_name, self.label = getData(mode)\n",
    "        self.mode = mode\n",
    "        print(\"> Found %d images...\" % (len(self.img_name)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #get the path and load the img \n",
    "        path = self.root + self.img_name[index] + '.jpeg' \n",
    "#         img  = mpimg.imread(path)\n",
    "        img  = Image.open(path).convert('RGB')\n",
    "\n",
    "        #get label according to indx\n",
    "        label = self.label[index]\n",
    "        \n",
    "        #set the trasnform\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5)\n",
    "        ])\n",
    "        \n",
    "        # Use transform make \n",
    "        img = transform(img)\n",
    "        # make the size 3*512*512 -> 1*3*512*512\n",
    "#         img = torch.unsqueeze(img, 0)\n",
    "        # get the tensor form label\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "\n",
    "#         img = transforms.Normalize(img,(0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         img = torchvision.transforms.ToPILImage(img)\n",
    "#         img = torchvision.transforms.ToTensor()(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "train_data = RetinopathyLoader(\"data/\", \"train\")\n",
    "test_data  = RetinopathyLoader(\"data/\", \"test\")\n",
    "\n",
    "train_data = DataLoader(train_data,batch_size=4,num_workers = 16,pin_memory = True)\n",
    "test_data = DataLoader(test_data,batch_size=4,num_workers = 16,pin_memory = True)\n",
    "\n",
    "# print(train_data[0][0].shape)\n",
    "# transform = transforms.Compose([transforms.ToPILImage()])\n",
    "# transforms.ToPILImage()(train_data[0][0][0]).show()\n",
    "# transform(train_data[0][0][0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8898e4-0986-4338-9b96-1342f2c01920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe9a67e-7dcf-42f3-8128-3b8263a99045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, m_type,pretrained=True):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.classify = nn.Linear(2048, 5)\n",
    "\n",
    "        pretrained_model = torchvision.models.__dict__['resnet{}'.format(m_type)](pretrained=pretrained)\n",
    "        self.conv1 = pretrained_model._modules['conv1']\n",
    "        self.bn1 = pretrained_model._modules['bn1']\n",
    "        self.relu = pretrained_model._modules['relu']\n",
    "        self.maxpool = pretrained_model._modules['maxpool']\n",
    "\n",
    "        self.layer1 = pretrained_model._modules['layer1']\n",
    "        self.layer2 = pretrained_model._modules['layer2']\n",
    "        self.layer3 = pretrained_model._modules['layer3']\n",
    "        self.layer4 = pretrained_model._modules['layer4']\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            pretrained_model._modules['fc'].in_features, 5\n",
    "        )\n",
    "        \n",
    "        del pretrained_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "#         print(\"before:\",x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(\"after:\",x.shape)\n",
    "        x = self.fc(x)\n",
    "#         print(\"final:\",x.shape)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3841a19-c073-4c6a-9ba9-4ba6149d5af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f42ada2-5ae8-4092-8cf8-e3524a757908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18_train(net):\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    for idx,pair in enumerate(train_data):\n",
    "        net.train()\n",
    "        inputs,labels = pair\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        # make gradients be zero , default is accumulated \n",
    "        optimizer.zero_grad()\n",
    "        #put the input to net , output size 1*1000 \n",
    "        outputs = net.forward(inputs)\n",
    "\n",
    "        #caclulate lose\n",
    "        loss = criterion(outputs, labels)\n",
    "#         print(loss.item())\n",
    "        #caculate gradient\n",
    "        loss.backward()\n",
    "        #using gradient update weight\n",
    "        optimizer.step()\n",
    "        #weight decay\n",
    "        for i in range(len(labels)):\n",
    "            ground_true = labels[i].item()\n",
    "            pred_y = torch.argmax(outputs[i]).item()\n",
    "    #         print(\"pred= \",pred_y)\n",
    "            confusion_yTrue.append(ground_true)\n",
    "            confusion_yPred.append(pred_y)\n",
    "        \n",
    "            if ground_true == pred_y:\n",
    "                true_ans = true_ans + 1\n",
    "            else:\n",
    "                false_ans = false_ans + 1\n",
    "                \n",
    "        if(idx!=0 and idx%100==0):\n",
    "            print(\"idx = \",idx,\"Train_accuracy = \",true_ans/(false_ans+true_ans))\n",
    "    return true_ans, false_ans, confusion_yTrue, confusion_yPred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6391dd6-2cd2-4d1d-be4d-da261e9348ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalutation(net):\n",
    "    net.eval()\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    for idx,pair in enumerate(test_data):\n",
    "        inputs,labels = pair\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            ground_true = labels[i].item()\n",
    "            pred_y = torch.argmax(outputs[i]).item()\n",
    "    #         print(\"pred= \",pred_y)\n",
    "            confusion_yTrue.append(ground_true)\n",
    "            confusion_yPred.append(pred_y)\n",
    "            if ground_true == pred_y:\n",
    "                true_ans = true_ans + 1\n",
    "            else:\n",
    "                false_ans = false_ans + 1\n",
    "                \n",
    "        if(idx!=0 and idx%100==0):\n",
    "            print(\"idx = \",idx,\"Eval_accuracy = \",true_ans/(false_ans+true_ans))\n",
    "            \n",
    "    return true_ans, false_ans, confusion_yTrue, confusion_yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfeb6a00-9201-4ca1-af59-51e993793353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(net,path):\n",
    "    print(\"Test the :\",path)\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    net.eval()\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    for idx,pair in enumerate(test_data):\n",
    "        inputs,labels = pair\n",
    "        inputs = inputs.float().to(device)\n",
    "        labels = labels.long().to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            ground_true = labels[i].item()\n",
    "            pred_y = torch.argmax(outputs[i]).item()\n",
    "    #         print(\"pred= \",pred_y)\n",
    "            confusion_yTrue.append(ground_true)\n",
    "            confusion_yPred.append(pred_y)\n",
    "            if ground_true == pred_y:\n",
    "                true_ans = true_ans + 1\n",
    "            else:\n",
    "                false_ans = false_ans + 1\n",
    "    if(idx!=0 and idx%100==0):\n",
    "        print(\"idx = \",idx,\"Eval_accuracy = \",true_ans/(false_ans+true_ans))\n",
    "    return true_ans/(false_ans+true_ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44d1ba2-4d93-47e5-b59d-5ef8b855eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "flag =\"\"\n",
    "def run(net):\n",
    "    global flag\n",
    "    if(net==pre_net):\n",
    "        print(\"pretrain network:\")\n",
    "        flag =\"pre\"\n",
    "    else:\n",
    "        print(\"newtrain network:\")\n",
    "        flag =\"new\"\n",
    "    train_epoch_list = []\n",
    "    train_acc_list = []\n",
    "    test_epoch_list = []\n",
    "    test_acc_list = []\n",
    "    f= open('ResNet18.txt','a')\n",
    "    for epoch in range(20):\n",
    "        print (\"Train: epoch \"+ str(epoch+1))\n",
    "        start = time.time()\n",
    "\n",
    "        #Traning\n",
    "        net.train()\n",
    "        train_epoch_list.append(epoch)\n",
    "#         result = ResNet18_train(net,len(train_data))\n",
    "        result = ResNet18_train(net)\n",
    "        train_y_true = result[2]\n",
    "        train_y_pred = result[3]\n",
    "        ACC = (result[0]/(result[0]+result[1]))\n",
    "        train_acc_list.append(ACC)\n",
    "        f.write(str(ACC)+\" \")\n",
    "        print (\"TrainAccuracy is : \"+str(ACC))\n",
    "\n",
    "        \n",
    "        #Testing\n",
    "        net.eval()\n",
    "        test_epoch_list.append(epoch)\n",
    "#         result = evalutation(net,test_data,len(test_data))\n",
    "        result = evalutation(net)\n",
    "        test_y_true = result[2]\n",
    "        test_y_pred = result[3]\n",
    "        ACC = (result[0]/(result[0]+result[1]))\n",
    "        test_acc_list.append(ACC)\n",
    "        f.write(str(ACC)+\"\\n\")\n",
    "        print (\"TestAccuracy is : \"+str(ACC))\n",
    "        end = time.time()\n",
    "        print(\"執行時間：%f 秒\" % (end - start))\n",
    "        if(ACC==max(test_acc_list)):\n",
    "            torch.save(net.state_dict(), \"CKPT/\"+flag+\"_ResNet18_final_ckpt\")\n",
    "    f.close()\n",
    "    return train_y_true,train_y_pred,test_y_true,test_y_pred,train_acc_list,test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0096f36e-8432-403e-9bea-4e39908eabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def plot_confusion_matrix(y_true,y_pred,title):\n",
    "    print(title+\":\")\n",
    "    cm = confusion_matrix(y_true,y_true,labels=[0,1,2,3,4])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=[0,1,2,3,4])\n",
    "    disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923cf51b-2cd5-48c0-b446-139ed05a15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImg():\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.plot(new_tran_accu,color=\"blue\",label=\"new_tran_accu\")\n",
    "    plt.plot(new_test_accu,color=\"orange\",label=\"new_test_accu\")\n",
    "    plt.plot(pretrain_tran_accu,color=\"green\",label=\"pretrain_tran_accu\")\n",
    "    plt.plot(pretrain_test_accu,color=\"red\",label=\"pretrain_test_accu\")\n",
    "    plt.title(\"ResNet18\")\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b5da9f-b920-4dfe-b3a5-71e1e57d4d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrain network:\n",
      "Train: epoch 1\n",
      "idx =  100 Train_accuracy =  0.7698019801980198\n",
      "idx =  200 Train_accuracy =  0.7524875621890548\n",
      "idx =  300 Train_accuracy =  0.7416943521594684\n",
      "idx =  400 Train_accuracy =  0.7412718204488778\n",
      "idx =  500 Train_accuracy =  0.7410179640718563\n",
      "idx =  600 Train_accuracy =  0.7400166389351082\n",
      "idx =  700 Train_accuracy =  0.7382310984308131\n",
      "idx =  800 Train_accuracy =  0.7393882646691635\n",
      "idx =  900 Train_accuracy =  0.7413984461709212\n",
      "idx =  1000 Train_accuracy =  0.743006993006993\n",
      "idx =  1100 Train_accuracy =  0.7411444141689373\n",
      "idx =  1200 Train_accuracy =  0.7404246461282264\n",
      "idx =  1300 Train_accuracy =  0.7390468870099923\n",
      "idx =  1400 Train_accuracy =  0.7380442541042113\n",
      "idx =  1500 Train_accuracy =  0.7348434377081945\n",
      "idx =  1600 Train_accuracy =  0.7343847595252967\n",
      "idx =  1700 Train_accuracy =  0.7338330393885949\n",
      "idx =  1800 Train_accuracy =  0.7345918933925597\n",
      "idx =  1900 Train_accuracy =  0.7354024197790636\n",
      "idx =  2000 Train_accuracy =  0.7348825587206397\n",
      "idx =  2100 Train_accuracy =  0.7344121846739647\n",
      "idx =  2200 Train_accuracy =  0.7353475692866879\n",
      "idx =  2300 Train_accuracy =  0.737070838765754\n",
      "idx =  2400 Train_accuracy =  0.7393794252394835\n",
      "idx =  2500 Train_accuracy =  0.7380047980807677\n",
      "idx =  2600 Train_accuracy =  0.738081507112649\n",
      "idx =  2700 Train_accuracy =  0.7379674194742688\n",
      "idx =  2800 Train_accuracy =  0.7378614780435558\n",
      "idx =  2900 Train_accuracy =  0.7387107893829714\n",
      "idx =  3000 Train_accuracy =  0.7387537487504166\n",
      "idx =  3100 Train_accuracy =  0.7379877458884231\n",
      "idx =  3200 Train_accuracy =  0.7376601062168072\n",
      "idx =  3300 Train_accuracy =  0.7374280521054226\n",
      "idx =  3400 Train_accuracy =  0.7369891208468098\n",
      "idx =  3500 Train_accuracy =  0.7368608968866038\n",
      "idx =  3600 Train_accuracy =  0.7370869202999167\n",
      "idx =  3700 Train_accuracy =  0.7366252364225885\n",
      "idx =  3800 Train_accuracy =  0.7367797947908445\n",
      "idx =  3900 Train_accuracy =  0.7371186875160215\n",
      "idx =  4000 Train_accuracy =  0.7371907023244189\n",
      "idx =  4100 Train_accuracy =  0.736588636917825\n",
      "idx =  4200 Train_accuracy =  0.7369673887169722\n",
      "idx =  4300 Train_accuracy =  0.7365147640083701\n",
      "idx =  4400 Train_accuracy =  0.7360827084753465\n",
      "idx =  4500 Train_accuracy =  0.7365029993334814\n",
      "idx =  4600 Train_accuracy =  0.7365790045642252\n",
      "idx =  4700 Train_accuracy =  0.7369708572644118\n",
      "idx =  4800 Train_accuracy =  0.737606748594043\n",
      "idx =  4900 Train_accuracy =  0.7376045704958172\n",
      "idx =  5000 Train_accuracy =  0.7378024395120976\n",
      "idx =  5100 Train_accuracy =  0.738482650460694\n",
      "idx =  5200 Train_accuracy =  0.7386079600076908\n",
      "idx =  5300 Train_accuracy =  0.7392001509149217\n",
      "idx =  5400 Train_accuracy =  0.7393538233660433\n",
      "idx =  5500 Train_accuracy =  0.7395473550263588\n",
      "idx =  5600 Train_accuracy =  0.7400464202820924\n",
      "idx =  5700 Train_accuracy =  0.7394755306086651\n",
      "idx =  5800 Train_accuracy =  0.7395276676435097\n",
      "idx =  5900 Train_accuracy =  0.7398745975258431\n",
      "idx =  6000 Train_accuracy =  0.740084985835694\n",
      "idx =  6100 Train_accuracy =  0.7400835928536306\n",
      "idx =  6200 Train_accuracy =  0.7397597161748105\n",
      "idx =  6300 Train_accuracy =  0.738970004761149\n",
      "idx =  6400 Train_accuracy =  0.7391813779097016\n",
      "idx =  6500 Train_accuracy =  0.7398477157360406\n",
      "idx =  6600 Train_accuracy =  0.7401530071201333\n",
      "idx =  6700 Train_accuracy =  0.7404118788240561\n",
      "idx =  6800 Train_accuracy =  0.7403323040729305\n",
      "idx =  6900 Train_accuracy =  0.7405448485726707\n",
      "idx =  7000 Train_accuracy =  0.7407870304242251\n",
      "TrainAccuracy is : 0.7407381045588811\n",
      "idx =  100 Eval_accuracy =  0.7648514851485149\n",
      "idx =  200 Eval_accuracy =  0.7686567164179104\n",
      "idx =  300 Eval_accuracy =  0.7441860465116279\n",
      "idx =  400 Eval_accuracy =  0.7456359102244389\n",
      "idx =  500 Eval_accuracy =  0.7400199600798403\n",
      "idx =  600 Eval_accuracy =  0.7508319467554077\n",
      "idx =  700 Eval_accuracy =  0.7578459343794579\n",
      "idx =  800 Eval_accuracy =  0.7581148564294632\n",
      "idx =  900 Eval_accuracy =  0.7572142064372919\n",
      "idx =  1000 Eval_accuracy =  0.7564935064935064\n",
      "idx =  1100 Eval_accuracy =  0.7590826521344233\n",
      "idx =  1200 Eval_accuracy =  0.7583263946711074\n",
      "idx =  1300 Eval_accuracy =  0.7598001537279017\n",
      "idx =  1400 Eval_accuracy =  0.7591006423982869\n",
      "idx =  1500 Eval_accuracy =  0.758327781479014\n",
      "idx =  1600 Eval_accuracy =  0.7573391630231106\n",
      "idx =  1700 Eval_accuracy =  0.7583774250440917\n",
      "TestAccuracy is : 0.757864768683274\n",
      "執行時間：858.633554 秒\n",
      "Train: epoch 2\n",
      "idx =  100 Train_accuracy =  0.7896039603960396\n",
      "idx =  200 Train_accuracy =  0.7711442786069652\n",
      "idx =  300 Train_accuracy =  0.7616279069767442\n",
      "idx =  400 Train_accuracy =  0.7624688279301746\n",
      "idx =  500 Train_accuracy =  0.7609780439121756\n",
      "idx =  600 Train_accuracy =  0.7587354409317804\n",
      "idx =  700 Train_accuracy =  0.7606990014265336\n",
      "idx =  800 Train_accuracy =  0.7609238451935081\n",
      "idx =  900 Train_accuracy =  0.7624861265260822\n",
      "idx =  1000 Train_accuracy =  0.7627372627372627\n",
      "idx =  1100 Train_accuracy =  0.7620345140781108\n",
      "idx =  1200 Train_accuracy =  0.761240632805995\n",
      "idx =  1300 Train_accuracy =  0.7594158339738662\n",
      "idx =  1400 Train_accuracy =  0.7578515346181299\n",
      "idx =  1500 Train_accuracy =  0.7551632245169887\n",
      "idx =  1600 Train_accuracy =  0.7556214865708932\n",
      "idx =  1700 Train_accuracy =  0.7554379776601999\n",
      "idx =  1800 Train_accuracy =  0.756246529705719\n",
      "idx =  1900 Train_accuracy =  0.7586796422935297\n",
      "idx =  2000 Train_accuracy =  0.7593703148425787\n",
      "idx =  2100 Train_accuracy =  0.7596382674916706\n",
      "idx =  2200 Train_accuracy =  0.7599954566106315\n",
      "idx =  2300 Train_accuracy =  0.761625380269448\n",
      "idx =  2400 Train_accuracy =  0.7637442732194919\n",
      "idx =  2500 Train_accuracy =  0.7630947620951619\n",
      "idx =  2600 Train_accuracy =  0.7632641291810842\n",
      "idx =  2700 Train_accuracy =  0.7638837467604591\n",
      "idx =  2800 Train_accuracy =  0.7638343448768297\n",
      "idx =  2900 Train_accuracy =  0.7646501206480524\n",
      "idx =  3000 Train_accuracy =  0.7651616127957348\n",
      "idx =  3100 Train_accuracy =  0.7635440180586908\n",
      "idx =  3200 Train_accuracy =  0.7636676038737894\n",
      "idx =  3300 Train_accuracy =  0.7637079672826417\n",
      "idx =  3400 Train_accuracy =  0.7635254336959718\n",
      "idx =  3500 Train_accuracy =  0.7637103684661525\n",
      "idx =  3600 Train_accuracy =  0.7638156067758956\n",
      "idx =  3700 Train_accuracy =  0.7630370170224263\n",
      "idx =  3800 Train_accuracy =  0.7632202052091555\n",
      "idx =  3900 Train_accuracy =  0.7635862599333504\n",
      "idx =  4000 Train_accuracy =  0.7637465633591602\n",
      "idx =  4100 Train_accuracy =  0.7631675201170446\n",
      "idx =  4200 Train_accuracy =  0.7636872173292073\n",
      "idx =  4300 Train_accuracy =  0.7631364798883981\n",
      "idx =  4400 Train_accuracy =  0.762610770279482\n",
      "idx =  4500 Train_accuracy =  0.7629971117529438\n",
      "idx =  4600 Train_accuracy =  0.7629863073244947\n",
      "idx =  4700 Train_accuracy =  0.7634014039566049\n",
      "idx =  4800 Train_accuracy =  0.7638512809831285\n",
      "idx =  4900 Train_accuracy =  0.7637216894511324\n",
      "idx =  5000 Train_accuracy =  0.7636472705458909\n",
      "idx =  5100 Train_accuracy =  0.7642619094295237\n",
      "idx =  5200 Train_accuracy =  0.7640357623533935\n",
      "idx =  5300 Train_accuracy =  0.7647613657800415\n",
      "idx =  5400 Train_accuracy =  0.7649046472875394\n",
      "idx =  5500 Train_accuracy =  0.7647245955280858\n",
      "idx =  5600 Train_accuracy =  0.7648634172469202\n",
      "idx =  5700 Train_accuracy =  0.7643395895456937\n",
      "idx =  5800 Train_accuracy =  0.7643940699879331\n",
      "idx =  5900 Train_accuracy =  0.7644467039484834\n",
      "idx =  6000 Train_accuracy =  0.764497583736044\n",
      "idx =  6100 Train_accuracy =  0.764792656941485\n",
      "idx =  6200 Train_accuracy =  0.7641912594742784\n",
      "idx =  6300 Train_accuracy =  0.7635295984764323\n",
      "idx =  6400 Train_accuracy =  0.7634744571160756\n",
      "idx =  6500 Train_accuracy =  0.7639209352407322\n",
      "idx =  6600 Train_accuracy =  0.7641266474776549\n",
      "idx =  6700 Train_accuracy =  0.7642889121026712\n",
      "idx =  6800 Train_accuracy =  0.7644464049404499\n",
      "idx =  6900 Train_accuracy =  0.7647804665990436\n",
      "idx =  7000 Train_accuracy =  0.7648550207113269\n",
      "TrainAccuracy is : 0.7647603117548667\n",
      "idx =  100 Eval_accuracy =  0.7673267326732673\n",
      "idx =  200 Eval_accuracy =  0.7786069651741293\n",
      "idx =  300 Eval_accuracy =  0.7599667774086378\n",
      "idx =  400 Eval_accuracy =  0.7605985037406484\n",
      "idx =  500 Eval_accuracy =  0.7539920159680639\n",
      "idx =  600 Eval_accuracy =  0.7641430948419301\n",
      "idx =  700 Eval_accuracy =  0.771398002853067\n",
      "idx =  800 Eval_accuracy =  0.7705992509363296\n",
      "idx =  900 Eval_accuracy =  0.7680355160932297\n",
      "idx =  1000 Eval_accuracy =  0.7672327672327672\n",
      "idx =  1100 Eval_accuracy =  0.7717983651226158\n",
      "idx =  1200 Eval_accuracy =  0.77248126561199\n",
      "idx =  1300 Eval_accuracy =  0.7732513451191392\n",
      "idx =  1400 Eval_accuracy =  0.7728408279800143\n",
      "idx =  1500 Eval_accuracy =  0.7723184543637575\n",
      "idx =  1600 Eval_accuracy =  0.7723297938788257\n",
      "idx =  1700 Eval_accuracy =  0.7736625514403292\n",
      "TestAccuracy is : 0.7732384341637011\n",
      "執行時間：863.434902 秒\n",
      "Train: epoch 3\n",
      "idx =  100 Train_accuracy =  0.8044554455445545\n",
      "idx =  200 Train_accuracy =  0.7848258706467661\n",
      "idx =  300 Train_accuracy =  0.7749169435215947\n",
      "idx =  400 Train_accuracy =  0.7755610972568578\n",
      "idx =  500 Train_accuracy =  0.7749500998003992\n",
      "idx =  600 Train_accuracy =  0.7732945091514143\n",
      "idx =  700 Train_accuracy =  0.7742510699001427\n",
      "idx =  800 Train_accuracy =  0.7740324594257179\n",
      "idx =  900 Train_accuracy =  0.7760821309655938\n",
      "idx =  1000 Train_accuracy =  0.7757242757242757\n",
      "idx =  1100 Train_accuracy =  0.7754314259763851\n",
      "idx =  1200 Train_accuracy =  0.7749791840133222\n",
      "idx =  1300 Train_accuracy =  0.7730591852421215\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 5.\nOriginal Traceback (most recent call last):\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-3-223d94ca7e15>\", line 17, in __getitem__\n    img  = Image.open(path).convert('RGB')\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/PIL/Image.py\", line 2912, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'data/36644_left.jpeg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-114f14fe7b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresult_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_old\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_old\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_old\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_old\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pretrain_train_confusion\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-da17cc972cc2>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_epoch_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#         result = ResNet18_train(net,len(train_data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet18_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_y_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtrain_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a2cd8bf74945>\u001b[0m in \u001b[0;36mResNet18_train\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfusion_yTrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconfusion_yPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 5.\nOriginal Traceback (most recent call last):\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-3-223d94ca7e15>\", line 17, in __getitem__\n    img  = Image.open(path).convert('RGB')\n  File \"/home/frank/miniconda3/envs/pytorch/lib/python3.9/site-packages/PIL/Image.py\", line 2912, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'data/36644_left.jpeg'\n"
     ]
    }
   ],
   "source": [
    "load=0\n",
    "pre_net = ResNet(18,True).to(device)\n",
    "net = ResNet(18,False).to(device)\n",
    "\n",
    "if(load==0):\n",
    "    #pretrain net\n",
    "    criterion = F.cross_entropy\n",
    "    optimizer = torch.optim.SGD(pre_net.parameters(), lr=1e-3,momentum=0.1,weight_decay=5e-4)\n",
    "    result_old = run(pre_net)\n",
    "    confusion_matrix(result_old[0],result_old[1],labels=[0,1,2,3,4])\n",
    "    plot_confusion_matrix(result_old[0],result_old[0],title=\"pretrain_train_confusion\")\n",
    "    plot_confusion_matrix(result_old[2],result_old[3],title=\"pretrain_test_confusion\")\n",
    "    pretrain_tran_accu = result_old[4]\n",
    "    pretrain_test_accu = result_old[5]\n",
    "\n",
    "    #new net\n",
    "    criterion = F.cross_entropy\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=1e-3,momentum=0.1,weight_decay=5e-4)\n",
    "    result_new = run(net)\n",
    "    plot_confusion_matrix(result_new[0],result_new[1],title=\"new_train_confusion\")\n",
    "    plot_confusion_matrix(result_new[2],result_new[3],title=\"new_test_confusion\")\n",
    "    new_tran_accu = result_new[4]\n",
    "    new_test_accu = result_new[5]\n",
    "\n",
    "else:\n",
    "    path = \"CKPT/pre_ResNet18_final_ckpt\"\n",
    "    print(validation(pre_net,path))\n",
    "    path = \"CKPT/new_ResNet18_final_ckpt\"\n",
    "    print(validation(net,path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7b271-f255-45be-8308-b321c2a83d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to set load = 0\n",
    "plotImg()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9.4",
   "language": "python",
   "name": "python3.9.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
